# ğŸ¥ Clinical AI Assistant

An AI-powered backend that processes doctorâ€“patient transcripts and generates structured clinical insights using Large Language Models (LLMs).

Deployed on **Render**, secured with **API key authentication**, and includes a **latency benchmarking** script for performance measurement.

---

## ğŸš€ Live Deployment

**API Base URL**
- https://clinical-ai-assistant-61ui.onrender.com

> Note: The `/generate` endpoint is protected. You must send a valid `X-API-KEY` header.

---

## âœ¨ Key Features

- ğŸ§  Converts raw medical conversations into structured outputs
- ğŸ” API key authentication via `X-API-KEY`
- â˜ï¸ Hosted on Render (cloud deployment)
- ğŸ“Š Latency benchmarking script included (`metrics/benchmark_latency.py`)
- ğŸ§ª Simple REST endpoint for transcript processing
- ğŸ›¡ï¸ Secrets handled via environment variables (`.env`) â€” no hardcoded keys

---

## ğŸ§± Tech Stack

- **Python 3.10+**
- Backend framework: **FastAPI / Flask** *(update this to whichever you used)*
- **OpenAI API** (LLM inference)
- **Render** (deployment)
- `python-dotenv` (env management)
- `requests` (benchmark script)

---

## ğŸ—‚ï¸ Project Structure (Typical)

> Your repo may vary slightlyâ€”update if needed.

```text
Clinical_AI_Assistant/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env                # NOT committed (local only)
â”‚
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ benchmark_latency.py
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```
---

## ğŸ” Authentication

All requests to protected endpoints (e.g., `/generate`) must include a valid API key in the request header.

### Required Header

`X-API-KEY: <your_api_key>`

If the API key is missing or incorrect, the server will return **401 Unauthorized**.

---

## ğŸ“¡ API Reference

### POST `/generate`

#### Headers
```json
{
  "Content-Type": "application/json",
  "X-API-KEY": "your_api_key"
}
```

#### Body
```json
{
  "text": "Doctor: What brings you in today? Patient: I have fever and cough..."
}
```

#### Example cURL
```bash
curl -X POST https://clinical-ai-assistant-61ui.onrender.com/generate \
  -H "Content-Type: application/json" \
  -H "X-API-KEY: your_api_key" \
  -d '{"text":"Doctor: What brings you in today? Patient: I have fever and cough."}'
```

---

## ğŸ§ª Local Setup

### 1) Clone the repository
```bash
git clone https://github.com/Amit-Kumar-KJ/Clinical_AI_Assistant.git
cd Clinical_AI_Assistant
```

### 2) Create & activate a virtual environment

Recommended: create the venv inside `backend/` since backend dependencies live there.

```bash
cd backend
python -m venv venv
```

Windows (PowerShell)
```bash
venv\Scripts\Activate.ps1
```

Windows (CMD)
```bash
venv\Scripts\activate.bat
```

macOS/Linux
```bash
source venv/bin/activate
```

### 3) Install dependencies
```bash
pip install -r requirements.txt
```

### 4) Create a `.env` file (IMPORTANT)

Create `backend/.env`:

```env
APP_API_KEY=your_secret_key_for_this_app
OPENAI_API_KEY=your_openai_key
```

Keep `.env` local only.  
Never commit `.env` to GitHub.

### 5) Run the backend

Replace the run command if your project uses uvicorn/FastAPI, etc.

If Flask-style
```bash
python app.py
```

If FastAPI + uvicorn
```bash
uvicorn app:app --reload
```

---

## ğŸ“Š Benchmarking (Latency Metrics)

This project includes a benchmarking script:

`metrics/benchmark_latency.py`

### Run benchmark

From repo root:
```bash
python metrics/benchmark_latency.py
```

Or:
```bash
cd metrics
python benchmark_latency.py
```

### What it measures

- Average latency  
- Min latency  
- Max latency  
- Standard deviation (jitter)  

Tip: Run at least 20â€“50 requests for a stable average, especially on Render free tier.

---

## ğŸ§¾ Resume-Ready Metrics Line

You can add a bullet like this (replace X with your benchmark result):

Deployed an AI-powered clinical transcript processing backend on Render, achieving ~X seconds average response latency per transcript request, secured via API-key authentication and environment-based secret management.

---

## ğŸ›¡ï¸ Security Notes

- API keys stored in environment variables  
- `.env` is ignored via `.gitignore`  
- Requests require `X-API-KEY` header  
- No secrets are hardcoded into source code  

---

## ğŸ—ºï¸ Roadmap / Future Improvements

- Add rate limiting (protect from abuse)  
- Add request logging + analytics dashboard  
- Add structured JSON output schema (validated)  
- Add Docker support + production config  
- Add CI/CD (GitHub Actions)  
- Add caching for frequent requests  
- Add unit tests & integration tests  

---

## ğŸ‘¨â€ğŸ’» Author

Amit Kumar  
GitHub: https://github.com/Amit-Kumar-KJ  

---

## â­ Support

If you find this project helpful, consider giving it a star on GitHub!